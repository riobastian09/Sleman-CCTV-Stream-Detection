{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "cv2.namedWindow(\"Prediksi Video\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "jenis_kendaraan = { 0: 'Mobil', 1: 'Motor'}\n",
    "model = YOLO('best.pt')\n",
    "model.fuse()\n",
    "# blob:http://103.71.191.168/507c9656-d9dc-4e1e-9ea4-383ceeac7521\n",
    "# lokasiVideo = \"http://103.71.191.168/8888/player.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object BasePredictor.stream_inference at 0x000001E9EC7F4580>\n",
      "<class 'generator'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(results)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(results))\n\u001b[1;32m----> 5\u001b[0m annotated_image \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mplot()\n\u001b[0;32m      7\u001b[0m cv2\u001b[39m.\u001b[39mnamedWindow(\u001b[39m\"\u001b[39m\u001b[39mPrediksi Video\u001b[39m\u001b[39m\"\u001b[39m, cv2\u001b[39m.\u001b[39mWINDOW_FREERATIO)\n\u001b[0;32m      8\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mPrediksi Video\u001b[39m\u001b[39m\"\u001b[39m, annotated_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    results = model.predict(lokasiVideo, conf=0.26, iou=0.8, stream=True)\n",
    "    print(results)\n",
    "    print(type(results))\n",
    "    annotated_image = results[0].plot()\n",
    "\n",
    "    cv2.namedWindow(\"Prediksi Video\", cv2.WINDOW_FREERATIO)\n",
    "    cv2.imshow(\"Prediksi Video\", annotated_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object BasePredictor.stream_inference at 0x000001E9ECB76CF0>\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(lokasiVideo, conf=0.26, iou=0.8, stream=True)\n",
    "print(results)\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(results[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "1/1: http://103.71.191.168/8888/player.html... Failed to open http://103.71.191.168/8888/player.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Infinite loop untuk memproses stream video\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mfor\u001b[39;00m path, im, pred \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mpredict(lokasiVideo, conf\u001b[39m=\u001b[39m\u001b[39m0.26\u001b[39m, iou\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m         \u001b[39m# Konversi BGR ke RGB\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(im, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     13\u001b[0m         \u001b[39m# Pred adalah tensor Nx6 dengan struktur [xyxy, conf, cls]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32md:\\PROGRESS TA\\Data Kak Yovi\\Prediksi\\ultralytics\\engine\\predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_model(model)\n\u001b[0;32m    228\u001b[0m \u001b[39m# Setup source every time predict is called\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_source(source \u001b[39mif\u001b[39;49;00m source \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49msource)\n\u001b[0;32m    231\u001b[0m \u001b[39m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_txt:\n",
      "File \u001b[1;32md:\\PROGRESS TA\\Data Kak Yovi\\Prediksi\\ultralytics\\engine\\predictor.py:210\u001b[0m, in \u001b[0;36mBasePredictor.setup_source\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgsz \u001b[39m=\u001b[39m check_imgsz(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mimgsz, stride\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstride, min_dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# check image size\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel, \u001b[39m'\u001b[39m\u001b[39mtransforms\u001b[39m\u001b[39m'\u001b[39m, classify_transforms(\n\u001b[0;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgsz[\u001b[39m0\u001b[39m])) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassify\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m load_inference_source(source\u001b[39m=\u001b[39;49msource, imgsz\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimgsz, vid_stride\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mvid_stride)\n\u001b[0;32m    211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39msource_type\n\u001b[0;32m    212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m  \u001b[39m# streams\u001b[39;00m\n\u001b[0;32m    213\u001b[0m                                           \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset) \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m \u001b[39mor\u001b[39;00m  \u001b[39m# images\u001b[39;00m\n\u001b[0;32m    214\u001b[0m                                           \u001b[39many\u001b[39m(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m'\u001b[39m\u001b[39mvideo_flag\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39mFalse\u001b[39;00m]))):  \u001b[39m# videos\u001b[39;00m\n",
      "File \u001b[1;32md:\\PROGRESS TA\\Data Kak Yovi\\Prediksi\\ultralytics\\data\\build.py:159\u001b[0m, in \u001b[0;36mload_inference_source\u001b[1;34m(source, imgsz, vid_stride)\u001b[0m\n\u001b[0;32m    157\u001b[0m     dataset \u001b[39m=\u001b[39m source\n\u001b[0;32m    158\u001b[0m \u001b[39melif\u001b[39;00m webcam:\n\u001b[1;32m--> 159\u001b[0m     dataset \u001b[39m=\u001b[39m LoadStreams(source, imgsz\u001b[39m=\u001b[39;49mimgsz, vid_stride\u001b[39m=\u001b[39;49mvid_stride)\n\u001b[0;32m    160\u001b[0m \u001b[39melif\u001b[39;00m screenshot:\n\u001b[0;32m    161\u001b[0m     dataset \u001b[39m=\u001b[39m LoadScreenshots(source, imgsz\u001b[39m=\u001b[39mimgsz)\n",
      "File \u001b[1;32md:\\PROGRESS TA\\Data Kak Yovi\\Prediksi\\ultralytics\\data\\loaders.py:56\u001b[0m, in \u001b[0;36mLoadStreams.__init__\u001b[1;34m(self, sources, imgsz, vid_stride)\u001b[0m\n\u001b[0;32m     54\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(s)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mst\u001b[39m}\u001b[39;00m\u001b[39mFailed to open \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m w \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(cap\u001b[39m.\u001b[39mget(cv2\u001b[39m.\u001b[39mCAP_PROP_FRAME_WIDTH))\n\u001b[0;32m     58\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(cap\u001b[39m.\u001b[39mget(cv2\u001b[39m.\u001b[39mCAP_PROP_FRAME_HEIGHT))\n",
      "\u001b[1;31mConnectionError\u001b[0m: 1/1: http://103.71.191.168/8888/player.html... Failed to open http://103.71.191.168/8888/player.html"
     ]
    }
   ],
   "source": [
    "# Lokasi stream video (ubah ke stream yang sesuai)\n",
    "lokasiVideo = \"http://103.71.191.168/8888/player.html\"\n",
    "\n",
    "# Jendela untuk menampilkan hasil\n",
    "cv2.namedWindow(\"Prediksi Video\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Infinite loop untuk memproses stream video\n",
    "try:\n",
    "    for path, im, pred in model.predict(lokasiVideo, conf=0.26, iou=0.8, stream=True):\n",
    "        # Konversi BGR ke RGB\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Pred adalah tensor Nx6 dengan struktur [xyxy, conf, cls]\n",
    "        for *xyxy, conf, cls in reversed(pred):\n",
    "            label = f'{model.names[int(cls)]} {conf:.2f}'\n",
    "            Annotator(im, line_width=2, example=str(model.names)).box_label(xyxy, label, color=(255, 0, 0))\n",
    "\n",
    "        # Tampilkan gambar\n",
    "        cv2.imshow(\"Prediksi Video\", im[:, :, ::-1])  # Konversi RGB ke BGR untuk OpenCV\n",
    "\n",
    "        # Break loop dengan menekan 'q'\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video stream.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Replace with your stream URL\n",
    "# lokasiVideo = \"http://103.71.191.168/8888/player.html\"\n",
    "STREAM_URL = \"http://103.71.191.168:8080/player.html\"\n",
    "\n",
    "def stream_video(url):\n",
    "    # Open a connection to the stream\n",
    "    cap = cv2.VideoCapture(url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Loop to continuously get frames\n",
    "        while True:\n",
    "            # Read a new frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "                break\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow('Video Stream', frame)\n",
    "\n",
    "            # Press 'q' to close the window\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        # Release the VideoCapture object and close windows\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stream_video(STREAM_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download: http://103.71.191.168/8888/hls/live.stream-257815.ts (Status code: 404)\n",
      "Failed to download: http://103.71.191.168/8888/hls/live.stream-257845.ts (Status code: 404)\n",
      "Stopped by the user.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Replace these with the appropriate values\n",
    "base_url = \"http://103.71.191.168/8888/hls/live.stream-{}.ts\"\n",
    "destination_folder = \"downloaded_ts\"  # Folder where you want to save the .ts files\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Function to download a single .ts file\n",
    "def download_ts_file(url, destination_path):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(destination_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:  # filter out keep-alive new chunks\n",
    "                        file.write(chunk)\n",
    "            print(f\"Downloaded: {destination_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {url} (Status code: {response.status_code})\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example of how to download files in a loop\n",
    "# Adjust the loop as needed based on how you update the timestamp 'X'\n",
    "i = 0\n",
    "try:\n",
    "    while True:\n",
    "        current_timestamp = int(time.time()) # Get current timestamp\n",
    "        file_name = f\"live.stream-{current_timestamp}.ts\"\n",
    "        ts_url = base_url.format(current_timestamp)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        \n",
    "        download_ts_file(ts_url, destination_path)\n",
    "        \n",
    "        # Wait for a bit before downloading the next file\n",
    "        # Adjust the sleep time as needed\n",
    "        time.sleep(10)\n",
    "        i+=20\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://103.71.191.168/8888/hls/live.stream-258212.ts\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# The URL from which you want to fetch data\n",
    "url = 'http://103.71.191.168/8888/hls/live.stream.m3u8'\n",
    "\n",
    "# Perform the GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Make sure the request was successful\n",
    "oldTs = 0\n",
    "if response.status_code == 200:\n",
    "    # Split the response text into lines\n",
    "    lines = response.text.strip().split('\\n')\n",
    "\n",
    "    \n",
    "    # Get the last line\n",
    "    last_line = lines[-1] if lines else None\n",
    "\n",
    "    currentUrl = f'http://103.71.191.168/8888/hls/{last_line}'\n",
    "\n",
    "    print(currentUrl)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode video stream.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# The URL of the .ts file\n",
    "url = 'http://103.71.191.168/8888/hls/live.stream-258212.ts'\n",
    "\n",
    "# Send a GET request to the server\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # The bytes of the video stream\n",
    "    video_bytes = bytes()\n",
    "\n",
    "    # Read in chunks to avoid using too much memory\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        video_bytes += chunk\n",
    "\n",
    "    with open('video.ts', 'wb') as file:\n",
    "        file.write(video_bytes)\n",
    "    \n",
    "    exit()\n",
    "    \n",
    "    # Convert the bytes to a numpy array\n",
    "    video_array = np.frombuffer(video_bytes, dtype=np.uint8)\n",
    "\n",
    "    # Use OpenCV to decode the video stream\n",
    "    video = cv2.imdecode(video_array, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Check if the video was successfully decoded\n",
    "    if video is not None:\n",
    "        # Here, you can process the video frame or display it\n",
    "        cv2.imshow('Frame', video)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Could not decode video stream.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve video: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
